{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "0817f48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "51a0752a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([[8,8,1], [7,9,1], [6,10,0], [5,5,0]], columns=['cgpa', 'resumeScore', 'placed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "1a89df01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cgpa</th>\n",
       "      <th>resumeScore</th>\n",
       "      <th>placed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cgpa  resumeScore  placed\n",
       "0     8            8       1\n",
       "1     7            9       1\n",
       "2     6           10       0\n",
       "3     5            5       0"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "a19cb9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialiseParameters(layerDimensions):\n",
    "    params = {}\n",
    "    L = len(layerDimensions)\n",
    "    for i in range(1, L):\n",
    "        params['W'+str(i)] = np.ones((layerDimensions[i-1], layerDimensions[i]))*0.1\n",
    "        params['b' + str(i)] = np.zeros((layerDimensions[i], 1))\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "01293f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def linearForward(A_prev, W, b):\n",
    "    Z = np.dot(W.T, A_prev) + b\n",
    "    r = 1/(1+math.e ** (-Z))\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "dbd3058b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# main Forward propogation function\n",
    "def LLayerForward(X, params):\n",
    "    A = X\n",
    "    L = len(params)//2\n",
    "    for l in range(1, L+1):\n",
    "        A_prev = A\n",
    "        Wl = params['W'+str(l)]\n",
    "        bl = params['b'+str(l)]\n",
    "        print('A'+str(l-1)+': ', A_prev)\n",
    "        print('W'+str(l)+': ', Wl)\n",
    "        print('b'+str(l)+': ', bl)\n",
    "        print('-'*40)\n",
    "        A = linearForward(A_prev, Wl, bl)\n",
    "        print('A'+str(l)+': ', A)\n",
    "        print('*'*40)\n",
    "    return A, A_prev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "7cdb84aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['cgpa', 'resumeScore']].values[0].reshape(2,1)\n",
    "y = df[['placed']].values[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "4ae43919",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A0:  [[8]\n",
      " [8]]\n",
      "W1:  [[0.1 0.1]\n",
      " [0.1 0.1]]\n",
      "b1:  [[0.]\n",
      " [0.]]\n",
      "----------------------------------------\n",
      "A1:  [[0.83201839]\n",
      " [0.83201839]]\n",
      "****************************************\n",
      "A1:  [[0.83201839]\n",
      " [0.83201839]]\n",
      "W2:  [[0.1]\n",
      " [0.1]]\n",
      "b2:  [[0.]]\n",
      "----------------------------------------\n",
      "A2:  [[0.54150519]]\n",
      "****************************************\n"
     ]
    }
   ],
   "source": [
    "params = initialiseParameters([2,2,1])\n",
    "y_hat, A1 = LLayerForward(X, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "dd702d99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5415051895671072"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat = y_hat[0][0]\n",
    "y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "8ab152e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.613402628898913"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = -y*np.log(y_hat)-(1-y)*np.log(1-y_hat)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "b1ba7bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateParams(params, y, y_hat, A1, X, lr):\n",
    "    # W2 n b2:\n",
    "    params['W2'][0][0] = params['W2'][0][0] + lr*((y-y_hat)*A1[0][0])\n",
    "    params['W2'][1][0] = params['W2'][1][0] + lr*((y-y_hat)*A1[1][0])\n",
    "    params['b2'][0][0] = params['b2'][0][0] + lr*((y-y_hat))\n",
    "    # W1 n b1    \n",
    "    params['W1'][0][0] = params['W1'][0][0] + lr*((y-y_hat)*params['W2'][0][0]*A1[0][0]*(1-A1[0][0])*X[0][0])\n",
    "    params['W1'][0][1] = params['W1'][0][1] + lr*((y-y_hat)*params['W2'][0][0]*A1[0][0]*(1-A1[0][0])*X[1][0])\n",
    "    params['b1'][0][0] = params['b1'][0][0] + lr*((y-y_hat)*params['W2'][0][0]*A1[0][0]*(1-A1[0][0]))\n",
    "\n",
    "    params['W1'][1][0] = params['W1'][1][0] + lr*((y-y_hat)*params['W2'][1][0]*A1[1][0]*(1-A1[1][0])*X[0][0])\n",
    "    params['W1'][1][1] = params['W1'][1][1] + lr*((y-y_hat)*params['W2'][1][0]*A1[1][0]*(1-A1[1][0])*X[1][0])\n",
    "    params['b1'][1][0] = params['b1'][1][0] + lr*((y-y_hat)*params['W2'][1][0]*A1[1][0]*(1-A1[1][0]))\n",
    "    return params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "98e998ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'W1': array([[0.10005146, 0.10005146],\n",
       "        [0.10005146, 0.10005146]]),\n",
       " 'b1': array([[6.43254269e-06],\n",
       "        [6.43254269e-06]]),\n",
       " 'W2': array([[0.10038148],\n",
       "        [0.10038148]]),\n",
       " 'b2': array([[0.00045849]])}"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = updateParams(params, y, y_hat, A1, X, 0.001)\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "6756c8f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "A0:  [[8]\n",
      " [8]]\n",
      "W1:  [[0.1 0.1]\n",
      " [0.1 0.1]]\n",
      "b1:  [[0.]\n",
      " [0.]]\n",
      "----------------------------------------\n",
      "A1:  [[0.83201839]\n",
      " [0.83201839]]\n",
      "****************************************\n",
      "A1:  [[0.83201839]\n",
      " [0.83201839]]\n",
      "W2:  [[0.1]\n",
      " [0.1]]\n",
      "b2:  [[0.]]\n",
      "----------------------------------------\n",
      "A2:  [[0.54150519]]\n",
      "****************************************\n",
      "A0:  [[7]\n",
      " [9]]\n",
      "W1:  [[0.10005146 0.10005146]\n",
      " [0.10005146 0.10005146]]\n",
      "b1:  [[6.43254269e-06]\n",
      " [6.43254269e-06]]\n",
      "----------------------------------------\n",
      "A1:  [[0.83213433]\n",
      " [0.83213433]]\n",
      "****************************************\n",
      "A1:  [[0.83213433]\n",
      " [0.83213433]]\n",
      "W2:  [[0.10038148]\n",
      " [0.10038148]]\n",
      "b2:  [[0.00045849]]\n",
      "----------------------------------------\n",
      "A2:  [[0.54178239]]\n",
      "****************************************\n",
      "A0:  [[ 6]\n",
      " [10]]\n",
      "W1:  [[0.10009661 0.10010951]\n",
      " [0.10009661 0.10010951]]\n",
      "b1:  [[1.28820601e-05]\n",
      " [1.28820601e-05]]\n",
      "----------------------------------------\n",
      "A1:  [[0.83223611]\n",
      " [0.83226492]]\n",
      "****************************************\n",
      "A1:  [[0.83223611]\n",
      " [0.83226492]]\n",
      "W2:  [[0.10076277]\n",
      " [0.10076277]]\n",
      "b2:  [[0.00091671]]\n",
      "----------------------------------------\n",
      "A2:  [[0.54205949]]\n",
      "****************************************\n",
      "A0:  [[5]\n",
      " [5]]\n",
      "W1:  [[0.10005106 0.10003359]\n",
      " [0.10005106 0.1000336 ]]\n",
      "b1:  [[5.29028411e-06]\n",
      " [5.29132637e-06]]\n",
      "----------------------------------------\n",
      "A1:  [[0.73116   ]\n",
      " [0.73112566]]\n",
      "****************************************\n",
      "A1:  [[0.73116   ]\n",
      " [0.73112566]]\n",
      "W2:  [[0.10031165]\n",
      " [0.10031164]]\n",
      "b2:  [[0.00037465]]\n",
      "----------------------------------------\n",
      "A2:  [[0.53669862]]\n",
      "****************************************\n",
      "Epoch: 1, Loss: 0.7693775060589632\n",
      "==================================================\n",
      "==================================================\n",
      "A0:  [[8]\n",
      " [8]]\n",
      "W1:  [[0.09999835 0.09998088]\n",
      " [0.09999835 0.09998089]]\n",
      "b1:  [[-5.25081553e-06]\n",
      " [-5.25062470e-06]]\n",
      "----------------------------------------\n",
      "A1:  [[0.83201397]\n",
      " [0.8319749 ]]\n",
      "****************************************\n",
      "A1:  [[0.83201397]\n",
      " [0.8319749 ]]\n",
      "W2:  [[0.09991924]\n",
      " [0.09991924]]\n",
      "b2:  [[-0.00016205]]\n",
      "----------------------------------------\n",
      "A2:  [[0.5414304]]\n",
      "****************************************\n",
      "A0:  [[7]\n",
      " [9]]\n",
      "W1:  [[0.10004978 0.10003231]\n",
      " [0.10004979 0.10003233]]\n",
      "b1:  [[1.17773925e-06]\n",
      " [1.17912207e-06]]\n",
      "----------------------------------------\n",
      "A1:  [[0.83212985]\n",
      " [0.83209081]]\n",
      "****************************************\n",
      "A1:  [[0.83212985]\n",
      " [0.83209081]]\n",
      "W2:  [[0.10030078]\n",
      " [0.10030076]]\n",
      "b2:  [[0.00029652]]\n",
      "----------------------------------------\n",
      "A2:  [[0.54170764]]\n",
      "****************************************\n",
      "A0:  [[ 6]\n",
      " [10]]\n",
      "W1:  [[0.1000949  0.10009032]\n",
      " [0.10009492 0.10009035]]\n",
      "b1:  [[7.62328373e-06]\n",
      " [7.62586094e-06]]\n",
      "----------------------------------------\n",
      "A1:  [[0.83223158]\n",
      " [0.83222137]]\n",
      "****************************************\n",
      "A1:  [[0.83223158]\n",
      " [0.83222137]]\n",
      "W2:  [[0.10068214]\n",
      " [0.1006821 ]]\n",
      "b2:  [[0.00075482]]\n",
      "----------------------------------------\n",
      "A2:  [[0.54198477]]\n",
      "****************************************\n",
      "A0:  [[5]\n",
      " [5]]\n",
      "W1:  [[0.10004939 0.10001447]\n",
      " [0.10004941 0.1000145 ]]\n",
      "b1:  [[3.84880217e-08]\n",
      " [4.06985840e-08]]\n",
      "----------------------------------------\n",
      "A1:  [[0.7311557 ]\n",
      " [0.73108706]]\n",
      "****************************************\n",
      "A1:  [[0.7311557 ]\n",
      " [0.73108706]]\n",
      "W2:  [[0.10023108]\n",
      " [0.10023105]]\n",
      "b2:  [[0.00021283]]\n",
      "----------------------------------------\n",
      "A2:  [[0.53662801]]\n",
      "****************************************\n",
      "Epoch: 2, Loss: 0.7692251192515712\n",
      "==================================================\n",
      "==================================================\n",
      "A0:  [[8]\n",
      " [8]]\n",
      "W1:  [[0.09999673 0.09996182]\n",
      " [0.09999674 0.09996183]]\n",
      "b1:  [[-1.04928378e-05]\n",
      " [-1.04923280e-05]]\n",
      "----------------------------------------\n",
      "A1:  [[0.83200962]\n",
      " [0.83193153]]\n",
      "****************************************\n",
      "A1:  [[0.83200962]\n",
      " [0.83193153]]\n",
      "W2:  [[0.09983872]\n",
      " [0.09983873]]\n",
      "b2:  [[-0.0003238]]\n",
      "----------------------------------------\n",
      "A2:  [[0.54135579]]\n",
      "****************************************\n",
      "A0:  [[7]\n",
      " [9]]\n",
      "W1:  [[0.10004813 0.10001321]\n",
      " [0.10004816 0.10001325]]\n",
      "b1:  [[-4.06826234e-06]\n",
      " [-4.06537094e-06]]\n",
      "----------------------------------------\n",
      "A1:  [[0.83212545]\n",
      " [0.8320474 ]]\n",
      "****************************************\n",
      "A1:  [[0.83212545]\n",
      " [0.8320474 ]]\n",
      "W2:  [[0.10022032]\n",
      " [0.10022029]]\n",
      "b2:  [[0.00013485]]\n",
      "----------------------------------------\n",
      "A2:  [[0.54163307]]\n",
      "****************************************\n",
      "A0:  [[ 6]\n",
      " [10]]\n",
      "W1:  [[0.10009322 0.10007119]\n",
      " [0.10009327 0.10007124]]\n",
      "b1:  [[2.37331776e-06]\n",
      " [2.37859553e-06]]\n",
      "----------------------------------------\n",
      "A1:  [[0.83222714]\n",
      " [0.83217792]]\n",
      "****************************************\n",
      "A1:  [[0.83222714]\n",
      " [0.83217792]]\n",
      "W2:  [[0.10060174]\n",
      " [0.10060167]]\n",
      "b2:  [[0.00059321]]\n",
      "----------------------------------------\n",
      "A2:  [[0.54191023]]\n",
      "****************************************\n",
      "A0:  [[5]\n",
      " [5]]\n",
      "W1:  [[0.10004775 0.09999541]\n",
      " [0.10004779 0.09999545]]\n",
      "b1:  [[-5.20451673e-06]\n",
      " [-5.20101085e-06]]\n",
      "----------------------------------------\n",
      "A1:  [[0.73115147]\n",
      " [0.73104857]]\n",
      "****************************************\n",
      "A1:  [[0.73115147]\n",
      " [0.73104857]]\n",
      "W2:  [[0.10015074]\n",
      " [0.10015071]]\n",
      "b2:  [[5.13043854e-05]]\n",
      "----------------------------------------\n",
      "A2:  [[0.53655757]]\n",
      "****************************************\n",
      "Epoch: 3, Loss: 0.7690731117472573\n",
      "==================================================\n",
      "==================================================\n",
      "A0:  [[8]\n",
      " [8]]\n",
      "W1:  [[0.09999515 0.0999428 ]\n",
      " [0.09999517 0.09994283]]\n",
      "b1:  [[-1.57260975e-05]\n",
      " [-1.57251395e-05]]\n",
      "----------------------------------------\n",
      "A1:  [[0.83200535]\n",
      " [0.83188826]]\n",
      "****************************************\n",
      "A1:  [[0.83200535]\n",
      " [0.83188826]]\n",
      "W2:  [[0.09975844]\n",
      " [0.09975846]]\n",
      "b2:  [[-0.00048525]]\n",
      "----------------------------------------\n",
      "A2:  [[0.54128136]]\n",
      "****************************************\n",
      "A0:  [[7]\n",
      " [9]]\n",
      "W1:  [[0.10004651 0.09999417]\n",
      " [0.10004656 0.09999422]]\n",
      "b1:  [[-9.30549268e-06]\n",
      " [-9.30096597e-06]]\n",
      "----------------------------------------\n",
      "A1:  [[0.83212113]\n",
      " [0.8320041 ]]\n",
      "****************************************\n",
      "A1:  [[0.83212113]\n",
      " [0.8320041 ]]\n",
      "W2:  [[0.10014009]\n",
      " [0.10014006]]\n",
      "b2:  [[-2.65345489e-05]]\n",
      "----------------------------------------\n",
      "A2:  [[0.54155867]]\n",
      "****************************************\n",
      "A0:  [[ 6]\n",
      " [10]]\n",
      "W1:  [[0.10009157 0.1000521 ]\n",
      " [0.10009165 0.10005219]]\n",
      "b1:  [[-2.86786840e-06]\n",
      " [-2.85976576e-06]]\n",
      "----------------------------------------\n",
      "A1:  [[0.83222277]\n",
      " [0.83213459]]\n",
      "****************************************\n",
      "A1:  [[0.83222277]\n",
      " [0.83213459]]\n",
      "W2:  [[0.10052157]\n",
      " [0.10052149]]\n",
      "b2:  [[0.00043191]]\n",
      "----------------------------------------\n",
      "A2:  [[0.54183587]]\n",
      "****************************************\n",
      "A0:  [[5]\n",
      " [5]]\n",
      "W1:  [[0.10004615 0.0999764 ]\n",
      " [0.1000462  0.09997645]]\n",
      "b1:  [[-1.04387607e-05]\n",
      " [-1.04338315e-05]]\n",
      "----------------------------------------\n",
      "A1:  [[0.73114731]\n",
      " [0.73101017]]\n",
      "****************************************\n",
      "A1:  [[0.73114731]\n",
      " [0.73101017]]\n",
      "W2:  [[0.10007065]\n",
      " [0.10007061]]\n",
      "b2:  [[-0.00010993]]\n",
      "----------------------------------------\n",
      "A2:  [[0.53648729]]\n",
      "****************************************\n",
      "Epoch: 4, Loss: 0.7689214825009097\n",
      "==================================================\n",
      "==================================================\n",
      "A0:  [[8]\n",
      " [8]]\n",
      "W1:  [[0.09999359 0.09992384]\n",
      " [0.09999363 0.09992387]]\n",
      "b1:  [[-2.09506251e-05]\n",
      " [-2.09490887e-05]]\n",
      "----------------------------------------\n",
      "A1:  [[0.83200116]\n",
      " [0.83184511]]\n",
      "****************************************\n",
      "A1:  [[0.83200116]\n",
      " [0.83184511]]\n",
      "W2:  [[0.09967839]\n",
      " [0.09967843]]\n",
      "b2:  [[-0.00064642]]\n",
      "----------------------------------------\n",
      "A2:  [[0.54120711]]\n",
      "****************************************\n",
      "A0:  [[7]\n",
      " [9]]\n",
      "W1:  [[0.10004492 0.09997517]\n",
      " [0.100045   0.09997524]]\n",
      "b1:  [[-1.45339823e-05]\n",
      " [-1.45276925e-05]]\n",
      "----------------------------------------\n",
      "A1:  [[0.83211688]\n",
      " [0.83196091]]\n",
      "****************************************\n",
      "A1:  [[0.83211688]\n",
      " [0.83196091]]\n",
      "W2:  [[0.10006011]\n",
      " [0.10006007]]\n",
      "b2:  [[-0.00018762]]\n",
      "----------------------------------------\n",
      "A2:  [[0.54148445]]\n",
      "****************************************\n",
      "A0:  [[ 6]\n",
      " [10]]\n",
      "W1:  [[0.10008996 0.10003307]\n",
      " [0.10009007 0.10003319]]\n",
      "b1:  [[-8.10030527e-06]\n",
      " [-8.08925243e-06]]\n",
      "----------------------------------------\n",
      "A1:  [[0.83221848]\n",
      " [0.83209136]]\n",
      "****************************************\n",
      "A1:  [[0.83221848]\n",
      " [0.83209136]]\n",
      "W2:  [[0.10044165]\n",
      " [0.10044154]]\n",
      "b2:  [[0.00027089]]\n",
      "----------------------------------------\n",
      "A2:  [[0.54176169]]\n",
      "****************************************\n",
      "A0:  [[5]\n",
      " [5]]\n",
      "W1:  [[0.10004457 0.09995743]\n",
      " [0.10004466 0.0999575 ]]\n",
      "b1:  [[-1.56642744e-05]\n",
      " [-1.56577929e-05]]\n",
      "----------------------------------------\n",
      "A1:  [[0.73114321]\n",
      " [0.73097187]]\n",
      "****************************************\n",
      "A1:  [[0.73114321]\n",
      " [0.73097187]]\n",
      "W2:  [[0.09999078]\n",
      " [0.09999074]]\n",
      "b2:  [[-0.00027087]]\n",
      "----------------------------------------\n",
      "A2:  [[0.53641718]]\n",
      "****************************************\n",
      "Epoch: 5, Loss: 0.7687702304707567\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# the final implementation\n",
    "def myNN():\n",
    "    result = []\n",
    "    params = initialiseParameters([2,2,1])\n",
    "    epochs = 5\n",
    "    for i in range(epochs):\n",
    "        print('='*50)\n",
    "        loss = []\n",
    "        for j in range(df.shape[0]):\n",
    "            X = df[['cgpa', 'resumeScore']].values[j].reshape(2,1)\n",
    "            y = df[['placed']].values[j][0]\n",
    "            y_hat, A1 = LLayerForward(X, params)\n",
    "            y_hat = y_hat[0][0]\n",
    "            params = updateParams(params, y, y_hat, A1, X, 0.001)\n",
    "            loss.append(-y*np.log(y_hat)-(1-y)*np.log(1-y_hat))\n",
    "        print(f'Epoch: {i+1}, Loss: { -y*np.log(y_hat)-(1-y)*np.log(1-y_hat)}')\n",
    "        result.append(f'Epoch: {i+1}, Loss: { -y*np.log(y_hat)-(1-y)*np.log(1-y_hat)}')\n",
    "        print('='*50)\n",
    "    return result, params\n",
    "res, params = myNN()        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "56d812ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss: 0.7693775060589632\n",
      "Epoch: 2, Loss: 0.7692251192515712\n",
      "Epoch: 3, Loss: 0.7690731117472573\n",
      "Epoch: 4, Loss: 0.7689214825009097\n",
      "Epoch: 5, Loss: 0.7687702304707567\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'W1': array([[0.09999206, 0.09990492],\n",
       "        [0.09999213, 0.09990497]]),\n",
       " 'b1': array([[-2.61664510e-05],\n",
       "        [-2.61642051e-05]]),\n",
       " 'W2': array([[0.09959859],\n",
       "        [0.09959864]]),\n",
       " 'b2': array([[-0.00080729]])}"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in res:\n",
    "    print(i)\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "e778bba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "a7d894c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "6626d838",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model.add(Dense(2, activation='sigmoid', input_dim=2))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "b5271961",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_4\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_4\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │             \u001b[38;5;34m6\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m3\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9</span> (36.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m9\u001b[0m (36.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9</span> (36.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m9\u001b[0m (36.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "b3325bc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.14973593,  1.0344151 ],\n",
       "        [-0.7065031 ,  1.216582  ]], dtype=float32),\n",
       " array([0., 0.], dtype=float32),\n",
       " array([[0.03506041],\n",
       "        [0.6382669 ]], dtype=float32),\n",
       " array([0.], dtype=float32)]"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "f87f9059",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_weights = [np.array([[0.1,0.1], [0.1,0.1]], dtype=np.float32), \n",
    "                np.array([0.,0.], dtype=np.float32),\n",
    "                np.array([[0.1], [0.1]], dtype=np.float32),\n",
    "                np.array([0.], dtype=np.float32)\n",
    "               ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "37876367",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.set_weights(new_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "3234a0c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0.1, 0.1],\n",
       "        [0.1, 0.1]], dtype=float32),\n",
       " array([0., 0.], dtype=float32),\n",
       " array([[0.1],\n",
       "        [0.1]], dtype=float32),\n",
       " array([0.], dtype=float32)]"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "8bd65e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(learning_rate=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "bdd7b081",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "a7c82654",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.7173\n",
      "Epoch 2/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6721 \n",
      "Epoch 3/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7317 \n",
      "Epoch 4/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.7128 \n",
      "Epoch 5/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6829  \n",
      "Epoch 6/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7307 \n",
      "Epoch 7/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6725 \n",
      "Epoch 8/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7020  \n",
      "Epoch 9/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7282 \n",
      "Epoch 10/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7121 \n",
      "Epoch 11/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7120 \n",
      "Epoch 12/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.6591 \n",
      "Epoch 13/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7276 \n",
      "Epoch 14/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6831 \n",
      "Epoch 15/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7053 \n",
      "Epoch 16/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7015 \n",
      "Epoch 17/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.6832 \n",
      "Epoch 18/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6842 \n",
      "Epoch 19/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.7113 \n",
      "Epoch 20/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7012 \n",
      "Epoch 21/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6750 \n",
      "Epoch 22/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.6750  \n",
      "Epoch 23/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6601 \n",
      "Epoch 24/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.7281 \n",
      "Epoch 25/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.6599 \n",
      "Epoch 26/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.7010  \n",
      "Epoch 27/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7254  \n",
      "Epoch 28/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7134 \n",
      "Epoch 29/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.7007 \n",
      "Epoch 30/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.7132  \n",
      "Epoch 31/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6835  \n",
      "Epoch 32/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6757  \n",
      "Epoch 33/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.6835\n",
      "Epoch 34/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6616 \n",
      "Epoch 35/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6836 \n",
      "Epoch 36/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6617 \n",
      "Epoch 37/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6836 \n",
      "Epoch 38/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6836 \n",
      "Epoch 39/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6743 \n",
      "Epoch 40/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6837 \n",
      "Epoch 41/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6617 \n",
      "Epoch 42/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7094 \n",
      "Epoch 43/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6620 \n",
      "Epoch 44/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6625 \n",
      "Epoch 45/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6625 \n",
      "Epoch 46/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7036 \n",
      "Epoch 47/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7245 \n",
      "Epoch 48/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7087 \n",
      "Epoch 49/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6839 \n",
      "Epoch 50/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6629 \n",
      "Epoch 51/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6751 \n",
      "Epoch 52/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.7114 \n",
      "Epoch 53/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6768  \n",
      "Epoch 54/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6996 \n",
      "Epoch 55/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6639 \n",
      "Epoch 56/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6752 \n",
      "Epoch 57/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7110 \n",
      "Epoch 58/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6994 \n",
      "Epoch 59/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7208 \n",
      "Epoch 60/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6842 \n",
      "Epoch 61/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6773 \n",
      "Epoch 62/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6992 \n",
      "Epoch 63/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6647 \n",
      "Epoch 64/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7203 \n",
      "Epoch 65/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6650 \n",
      "Epoch 66/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6773 \n",
      "Epoch 67/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6773 \n",
      "Epoch 68/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7074 \n",
      "Epoch 69/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7195  \n",
      "Epoch 70/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7070 \n",
      "Epoch 71/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6658 \n",
      "Epoch 72/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6655 \n",
      "Epoch 73/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6762 \n",
      "Epoch 74/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6853 \n",
      "Epoch 75/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6763 \n"
     ]
    }
   ],
   "source": [
    "h = model.fit(df.iloc[:, 0:-1].values, df['placed'].values, epochs=75, verbose=1, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "810e3284",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0.10225239, 0.10225239],\n",
       "        [0.08044203, 0.08044203]], dtype=float32),\n",
       " array([-0.04450627, -0.04450627], dtype=float32),\n",
       " array([[0.08852869],\n",
       "        [0.08852869]], dtype=float32),\n",
       " array([-0.0210135], dtype=float32)]"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19aa82f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
