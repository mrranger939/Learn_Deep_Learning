{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47ae694d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d6a0fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([[8,8,4], [7,9,5], [6,10,6], [5,12,7]], columns=['cgpa', 'resumeScore', 'lpa'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cfb5999f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cgpa</th>\n",
       "      <th>resumeScore</th>\n",
       "      <th>lpa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cgpa  resumeScore  lpa\n",
       "0     8            8    4\n",
       "1     7            9    5\n",
       "2     6           10    6\n",
       "3     5           12    7"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ce719d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialiseParameters(layerDimensions):\n",
    "    params = {}\n",
    "    L = len(layerDimensions)\n",
    "    for i in range(1, L):\n",
    "        params['W'+str(i)] = np.ones((layerDimensions[i-1], layerDimensions[i]))*0.1\n",
    "        params['b' + str(i)] = np.zeros((layerDimensions[i], 1))\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e27f412f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'W1': array([[0.1, 0.1],\n",
       "        [0.1, 0.1]]),\n",
       " 'b1': array([[0.],\n",
       "        [0.]]),\n",
       " 'W2': array([[0.1],\n",
       "        [0.1]]),\n",
       " 'b2': array([[0.]])}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initialiseParameters([2,2,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b457c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linearForward(A_prev, W, b):\n",
    "    Z = np.dot(W.T, A_prev) + b\n",
    "    return Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ee0ce84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# main Forward propogation function\n",
    "def LLayerForward(X, params):\n",
    "    A = X\n",
    "    L = len(params)//2\n",
    "    for l in range(1, L+1):\n",
    "        A_prev = A\n",
    "        Wl = params['W'+str(l)]\n",
    "        bl = params['b'+str(l)]\n",
    "        print('A'+str(l-1)+': ', A_prev)\n",
    "        print('W'+str(l)+': ', Wl)\n",
    "        print('b'+str(l)+': ', bl)\n",
    "        print('-'*40)\n",
    "        A = linearForward(A_prev, Wl, bl)\n",
    "        print('A'+str(l)+': ', A)\n",
    "        print('*'*40)\n",
    "    return A, A_prev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4527280f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['cgpa', 'resumeScore']].values[0].reshape(2,1)\n",
    "y = df[['lpa']].values[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "49b600f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A0:  [[8]\n",
      " [8]]\n",
      "W1:  [[0.1 0.1]\n",
      " [0.1 0.1]]\n",
      "b1:  [[0.]\n",
      " [0.]]\n",
      "----------------------------------------\n",
      "A1:  [[1.6]\n",
      " [1.6]]\n",
      "****************************************\n",
      "A1:  [[1.6]\n",
      " [1.6]]\n",
      "W2:  [[0.1]\n",
      " [0.1]]\n",
      "b2:  [[0.]]\n",
      "----------------------------------------\n",
      "A2:  [[0.32]]\n",
      "****************************************\n"
     ]
    }
   ],
   "source": [
    "params = initialiseParameters([2,2,1])\n",
    "y_hat, A1 = LLayerForward(X, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2207c7d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13.542399999999997"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat = y_hat[0][0]\n",
    "(y-y_hat)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9952d7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateParams(params, y, y_hat, A1, X, lr):\n",
    "    # W2 n b2:\n",
    "    params['W2'][0][0] = params['W2'][0][0] + lr*(2*(y-y_hat)*A1[0][0])\n",
    "    params['W2'][1][0] = params['W2'][1][0] + lr*(2*(y-y_hat)*A1[1][0])\n",
    "    params['b2'][0][0] = params['b2'][0][0] + lr*(2*(y-y_hat))\n",
    "    # W1 n b1:\n",
    "    params['W1'][0][0] = params['W1'][0][0] + lr*(2*(y-y_hat)*params['W2'][0][0]*X[0][0])\n",
    "    params['W1'][0][1] = params['W1'][0][1] + lr*(2*(y-y_hat)*params['W2'][0][0]*X[1][0])\n",
    "    params['b1'][0][0] = params['b1'][0][0] + lr*(2*(y-y_hat)*params['W2'][0][0])\n",
    "    \n",
    "    params['W1'][1][0] = params['W1'][1][0] + lr*(2*(y-y_hat)*params['W2'][1][0]*X[0][0])\n",
    "    params['W1'][1][1] = params['W1'][1][1] + lr*(2*(y-y_hat)*params['W2'][1][0]*X[1][0])\n",
    "    params['b1'][1][0] = params['b1'][1][0] + lr*(2*(y-y_hat)*params['W2'][1][0])\n",
    "    return params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "baccfc6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'W1': array([[0.10658137, 0.10658137],\n",
       "        [0.10658137, 0.10658137]]),\n",
       " 'b1': array([[0.00082267],\n",
       "        [0.00082267]]),\n",
       " 'W2': array([[0.111776],\n",
       "        [0.111776]]),\n",
       " 'b2': array([[0.00736]])}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = updateParams(params, y, y_hat, A1, X, 0.001)\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5da7dc27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "A0:  [[8]\n",
      " [8]]\n",
      "W1:  [[0.1 0.1]\n",
      " [0.1 0.1]]\n",
      "b1:  [[0.]\n",
      " [0.]]\n",
      "----------------------------------------\n",
      "A1:  [[1.6]\n",
      " [1.6]]\n",
      "****************************************\n",
      "A1:  [[1.6]\n",
      " [1.6]]\n",
      "W2:  [[0.1]\n",
      " [0.1]]\n",
      "b2:  [[0.]]\n",
      "----------------------------------------\n",
      "A2:  [[0.32]]\n",
      "****************************************\n",
      "A0:  [[7]\n",
      " [9]]\n",
      "W1:  [[0.10658137 0.10658137]\n",
      " [0.10658137 0.10658137]]\n",
      "b1:  [[0.00082267]\n",
      " [0.00082267]]\n",
      "----------------------------------------\n",
      "A1:  [[1.70612461]\n",
      " [1.70612461]]\n",
      "****************************************\n",
      "A1:  [[1.70612461]\n",
      " [1.70612461]]\n",
      "W2:  [[0.111776]\n",
      " [0.111776]]\n",
      "b2:  [[0.00736]]\n",
      "----------------------------------------\n",
      "A2:  [[0.38876757]]\n",
      "****************************************\n",
      "A0:  [[ 6]\n",
      " [10]]\n",
      "W1:  [[0.11481311 0.11716504]\n",
      " [0.11481311 0.11716504]]\n",
      "b1:  [[0.00199863]\n",
      " [0.00199863]]\n",
      "----------------------------------------\n",
      "A1:  [[1.83900839]\n",
      " [1.8766392 ]]\n",
      "****************************************\n",
      "A1:  [[1.83900839]\n",
      " [1.8766392 ]]\n",
      "W2:  [[0.12751067]\n",
      " [0.12751067]]\n",
      "b2:  [[0.01658246]]\n",
      "----------------------------------------\n",
      "A2:  [[0.49036719]]\n",
      "****************************************\n",
      "A0:  [[ 5]\n",
      " [12]]\n",
      "W1:  [[0.12458335 0.13344878]\n",
      " [0.12461077 0.13349447]]\n",
      "b1:  [[0.00362701]\n",
      " [0.00363158]]\n",
      "----------------------------------------\n",
      "A1:  [[2.12187303]\n",
      " [2.2728091 ]]\n",
      "****************************************\n",
      "A1:  [[2.12187303]\n",
      " [2.2728091 ]]\n",
      "W2:  [[0.1477752 ]\n",
      " [0.14818986]]\n",
      "b2:  [[0.02760173]]\n",
      "----------------------------------------\n",
      "A2:  [[0.6779692]]\n",
      "****************************************\n",
      "Epoch: 1, Loss: 26.28249792398698\n",
      "==================================================\n",
      "==================================================\n",
      "A0:  [[8]\n",
      " [8]]\n",
      "W1:  [[0.13562189 0.15994127]\n",
      " [0.13579618 0.16033944]]\n",
      "b1:  [[0.00583472]\n",
      " [0.00586866]]\n",
      "----------------------------------------\n",
      "A1:  [[2.17717925]\n",
      " [2.56811431]]\n",
      "****************************************\n",
      "A1:  [[2.17717925]\n",
      " [2.56811431]]\n",
      "W2:  [[0.17460429]\n",
      " [0.1769274 ]]\n",
      "b2:  [[0.04024579]]\n",
      "----------------------------------------\n",
      "A2:  [[0.87476041]]\n",
      "****************************************\n",
      "A0:  [[7]\n",
      " [9]]\n",
      "W1:  [[0.14503325 0.16935262]\n",
      " [0.14544588 0.16998915]]\n",
      "b1:  [[0.00701114]\n",
      " [0.00707487]]\n",
      "----------------------------------------\n",
      "A1:  [[2.33125681]\n",
      " [2.72244555]]\n",
      "****************************************\n",
      "A1:  [[2.33125681]\n",
      " [2.72244555]]\n",
      "W2:  [[0.1882127 ]\n",
      " [0.19297934]]\n",
      "b2:  [[0.04649627]]\n",
      "----------------------------------------\n",
      "A2:  [[1.01064417]]\n",
      "****************************************\n",
      "A0:  [[ 6]\n",
      " [10]]\n",
      "W1:  [[0.15658396 0.18420354]\n",
      " [0.15743714 0.18540648]]\n",
      "b1:  [[0.00866124]\n",
      " [0.00878791]]\n",
      "----------------------------------------\n",
      "A1:  [[2.52253643]\n",
      " [2.96807397]]\n",
      "****************************************\n",
      "A1:  [[2.52253643]\n",
      " [2.96807397]]\n",
      "W2:  [[0.20681313]\n",
      " [0.21470095]]\n",
      "b2:  [[0.05447498]]\n",
      "----------------------------------------\n",
      "A2:  [[1.21341694]]\n",
      "****************************************\n",
      "A0:  [[ 5]\n",
      " [12]]\n",
      "W1:  [[0.16985018 0.2063139 ]\n",
      " [0.17140141 0.20868027]]\n",
      "b1:  [[0.01087227]\n",
      " [0.01111529]]\n",
      "----------------------------------------\n",
      "A1:  [[2.91694011]\n",
      " [3.54684797]]\n",
      "****************************************\n",
      "A1:  [[2.91694011]\n",
      " [3.54684797]]\n",
      "W2:  [[0.23096179]\n",
      " [0.24311482]]\n",
      "b2:  [[0.06404815]]\n",
      "----------------------------------------\n",
      "A2:  [[1.60004115]]\n",
      "****************************************\n",
      "Epoch: 2, Loss: 19.438253848220803\n",
      "==================================================\n",
      "==================================================\n",
      "A0:  [[8]\n",
      " [8]]\n",
      "W1:  [[0.18402315 0.24032904]\n",
      " [0.186598   0.24515208]]\n",
      "b1:  [[0.01370687]\n",
      " [0.01415461]]\n",
      "----------------------------------------\n",
      "A1:  [[2.97867611]\n",
      " [3.89800358]]\n",
      "****************************************\n",
      "A1:  [[2.97867611]\n",
      " [3.89800358]]\n",
      "W2:  [[0.2624645 ]\n",
      " [0.28142048]]\n",
      "b2:  [[0.07484807]]\n",
      "----------------------------------------\n",
      "A2:  [[1.95362286]]\n",
      "****************************************\n",
      "A0:  [[7]\n",
      " [9]]\n",
      "W1:  [[0.19301593 0.24932182]\n",
      " [0.19633463 0.25488871]]\n",
      "b1:  [[0.01483097]\n",
      " [0.01537168]]\n",
      "----------------------------------------\n",
      "A1:  [[3.1329542 ]\n",
      " [4.05462284]]\n",
      "****************************************\n",
      "A1:  [[3.1329542 ]\n",
      " [4.05462284]]\n",
      "W2:  [[0.27465549]\n",
      " [0.29737405]]\n",
      "b2:  [[0.07894082]]\n",
      "----------------------------------------\n",
      "A2:  [[2.14516353]]\n",
      "****************************************\n",
      "A0:  [[ 6]\n",
      " [10]]\n",
      "W1:  [[0.20470823 0.26435477]\n",
      " [0.20914527 0.27135953]]\n",
      "b1:  [[0.01650129]\n",
      " [0.01720178]]\n",
      "----------------------------------------\n",
      "A1:  [[3.33620338]\n",
      " [4.31692573]]\n",
      "****************************************\n",
      "A1:  [[3.33620338]\n",
      " [4.31692573]]\n",
      "W2:  [[0.29254364]\n",
      " [0.32052462]]\n",
      "b2:  [[0.08465049]]\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A2:  [[2.44431656]]\n",
      "****************************************\n",
      "A0:  [[ 5]\n",
      " [12]]\n",
      "W1:  [[0.21820284 0.2868458 ]\n",
      " [0.22413136 0.29633635]]\n",
      "b1:  [[0.0187504 ]\n",
      " [0.01969946]]\n",
      "----------------------------------------\n",
      "A1:  [[3.79934094]\n",
      " [5.00996462]]\n",
      "****************************************\n",
      "A1:  [[3.79934094]\n",
      " [5.00996462]]\n",
      "W2:  [[0.3162686 ]\n",
      " [0.35122387]]\n",
      "b2:  [[0.09176186]]\n",
      "----------------------------------------\n",
      "A2:  [[3.05299325]]\n",
      "****************************************\n",
      "Epoch: 3, Loss: 10.139874435827522\n",
      "==================================================\n",
      "==================================================\n",
      "A0:  [[8]\n",
      " [8]]\n",
      "W1:  [[0.23186978 0.31964643]\n",
      " [0.23955518 0.33335352]]\n",
      "b1:  [[0.02148378]\n",
      " [0.02278422]]\n",
      "----------------------------------------\n",
      "A1:  [[3.79288343]\n",
      " [5.24678381]]\n",
      "****************************************\n",
      "A1:  [[3.79288343]\n",
      " [5.24678381]]\n",
      "W2:  [[0.34626065]\n",
      " [0.39077259]]\n",
      "b2:  [[0.09965587]]\n",
      "----------------------------------------\n",
      "A2:  [[3.46328148]]\n",
      "****************************************\n",
      "A0:  [[7]\n",
      " [9]]\n",
      "W1:  [[0.23487825 0.32265491]\n",
      " [0.2429593  0.33675764]]\n",
      "b1:  [[0.02185984]\n",
      " [0.02320974]]\n",
      "----------------------------------------\n",
      "A1:  [[3.85264134]\n",
      " [5.31261285]]\n",
      "****************************************\n",
      "A1:  [[3.85264134]\n",
      " [5.31261285]]\n",
      "W2:  [[0.35033207]\n",
      " [0.39640469]]\n",
      "b2:  [[0.10072931]]\n",
      "----------------------------------------\n",
      "A2:  [[3.55637777]]\n",
      "****************************************\n",
      "A0:  [[ 6]\n",
      " [10]]\n",
      "W1:  [[0.24218353 0.3320474 ]\n",
      " [0.25128093 0.34745688]]\n",
      "b1:  [[0.02290345]\n",
      " [0.02439854]]\n",
      "----------------------------------------\n",
      "A1:  [[3.98881394]\n",
      " [5.49125174]]\n",
      "****************************************\n",
      "A1:  [[3.98881394]\n",
      " [5.49125174]]\n",
      "W2:  [[0.36145559]\n",
      " [0.4117435 ]]\n",
      "b2:  [[0.10361656]]\n",
      "----------------------------------------\n",
      "A2:  [[3.80638285]]\n",
      "****************************************\n",
      "A0:  [[ 5]\n",
      " [12]]\n",
      "W1:  [[0.25215892 0.34867307]\n",
      " [0.26275359 0.36657798]]\n",
      "b1:  [[0.02456602]\n",
      " [0.02631065]]\n",
      "----------------------------------------\n",
      "A1:  [[4.43840374]\n",
      " [6.16861171]]\n",
      "****************************************\n",
      "A1:  [[4.43840374]\n",
      " [6.16861171]]\n",
      "W2:  [[0.37895545]\n",
      " [0.43583491]]\n",
      "b2:  [[0.10800379]]\n",
      "----------------------------------------\n",
      "A2:  [[4.47845739]]\n",
      "****************************************\n",
      "Epoch: 4, Loss: 3.385561305106485\n",
      "==================================================\n",
      "==================================================\n",
      "A0:  [[8]\n",
      " [8]]\n",
      "W1:  [[0.26227885 0.37296089]\n",
      " [0.27452778 0.39483602]]\n",
      "b1:  [[0.02659   ]\n",
      " [0.02866549]]\n",
      "----------------------------------------\n",
      "A1:  [[4.32104303]\n",
      " [6.17104077]]\n",
      "****************************************\n",
      "A1:  [[4.32104303]\n",
      " [6.17104077]]\n",
      "W2:  [[0.4013387 ]\n",
      " [0.46694374]]\n",
      "b2:  [[0.11304688]]\n",
      "----------------------------------------\n",
      "A2:  [[4.72877753]]\n",
      "****************************************\n",
      "A0:  [[7]\n",
      " [9]]\n",
      "W1:  [[0.2576725  0.36835454]\n",
      " [0.26918789 0.38949613]]\n",
      "b1:  [[0.02601421]\n",
      " [0.027998  ]]\n",
      "----------------------------------------\n",
      "A1:  [[4.25241274]\n",
      " [6.111945  ]]\n",
      "****************************************\n",
      "A1:  [[4.25241274]\n",
      " [6.111945  ]]\n",
      "W2:  [[0.39504054]\n",
      " [0.45794911]]\n",
      "b2:  [[0.11158932]]\n",
      "----------------------------------------\n",
      "A2:  [[4.59042452]]\n",
      "****************************************\n",
      "A0:  [[ 6]\n",
      " [10]]\n",
      "W1:  [[0.25995766 0.3712926 ]\n",
      " [0.2718425  0.39290921]]\n",
      "b1:  [[0.02634066]\n",
      " [0.02837723]]\n",
      "----------------------------------------\n",
      "A1:  [[4.30451167]\n",
      " [6.18522495]]\n",
      "****************************************\n",
      "A1:  [[4.30451167]\n",
      " [6.18522495]]\n",
      "W2:  [[0.39852391]\n",
      " [0.46295572]]\n",
      "b2:  [[0.11240847]]\n",
      "----------------------------------------\n",
      "A2:  [[4.69134453]]\n",
      "****************************************\n",
      "A0:  [[ 5]\n",
      " [12]]\n",
      "W1:  [[0.26639295 0.38201809]\n",
      " [0.27936692 0.40544991]]\n",
      "b1:  [[0.02741321]\n",
      " [0.0296313 ]]\n",
      "----------------------------------------\n",
      "A1:  [[4.71178104]\n",
      " [6.80512062]]\n",
      "****************************************\n",
      "A1:  [[4.71178104]\n",
      " [6.80512062]]\n",
      "W2:  [[0.40979015]\n",
      " [0.47914437]]\n",
      "b2:  [[0.11502578]]\n",
      "----------------------------------------\n",
      "A2:  [[5.30650251]]\n",
      "****************************************\n",
      "Epoch: 5, Loss: 1.3198454128484567\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# the final implementation\n",
    "def myNN():\n",
    "    result = []\n",
    "    params = initialiseParameters([2,2,1])\n",
    "    epochs = 5\n",
    "    for i in range(epochs):\n",
    "        print('='*50)\n",
    "        loss = []\n",
    "        for j in range(df.shape[0]):\n",
    "            X = df[['cgpa', 'resumeScore']].values[j].reshape(2,1)\n",
    "            y = df[['lpa']].values[j][0]\n",
    "            y_hat, A1 = LLayerForward(X, params)\n",
    "            y_hat = y_hat[0][0]\n",
    "            params = updateParams(params, y, y_hat, A1, X, 0.001)\n",
    "            loss.append((y-y_hat)**2)\n",
    "        print(f'Epoch: {i+1}, Loss: {np.array(loss).mean()}')\n",
    "        result.append(f'Epoch: {i+1}, Loss: {np.array(loss).mean()}')\n",
    "        print('='*50)\n",
    "    return result, params\n",
    "res, params = myNN()        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "26700d20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss: 26.28249792398698\n",
      "Epoch: 2, Loss: 19.438253848220803\n",
      "Epoch: 3, Loss: 10.139874435827522\n",
      "Epoch: 4, Loss: 3.385561305106485\n",
      "Epoch: 5, Loss: 1.3198454128484567\n"
     ]
    }
   ],
   "source": [
    "for i in res:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4ff603e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'W1': array([[0.273603  , 0.3993222 ],\n",
      "       [0.28787155, 0.42586102]]), 'b1': array([[0.02885522],\n",
      "       [0.03133223]]), 'W2': array([[0.42574893],\n",
      "       [0.50219328]]), 'b2': array([[0.11841278]])}\n"
     ]
    }
   ],
   "source": [
    "print(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c66f9633",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "acf901be",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5d614fe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model.add(Dense(2, activation='linear', input_dim=2))\n",
    "model.add(Dense(1, activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d8a2efab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │             \u001b[38;5;34m6\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m3\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9</span> (36.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m9\u001b[0m (36.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9</span> (36.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m9\u001b[0m (36.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cb6d9097",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.64014065,  0.06617236],\n",
       "        [-0.6089782 ,  0.47459257]], dtype=float32),\n",
       " array([0., 0.], dtype=float32),\n",
       " array([[ 0.45024335],\n",
       "        [-0.87838143]], dtype=float32),\n",
       " array([0.], dtype=float32)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e7469e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_weights = [np.array([[0.1,0.1], [0.1,0.1]], dtype=np.float32), \n",
    "                np.array([0.,0.], dtype=np.float32),\n",
    "                np.array([[0.1], [0.1]], dtype=np.float32),\n",
    "                np.array([0.], dtype=np.float32)\n",
    "               ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1f9a517d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.set_weights(new_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0367731b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0.1, 0.1],\n",
       "        [0.1, 0.1]], dtype=float32),\n",
       " array([0., 0.], dtype=float32),\n",
       " array([[0.1],\n",
       "        [0.1]], dtype=float32),\n",
       " array([0.], dtype=float32)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4a80dd26",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(learning_rate=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cccbb0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mean_squared_error', optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b16e496f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 31.9603\n",
      "Epoch 2/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 22.4197  \n",
      "Epoch 3/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 31.1265  \n",
      "Epoch 4/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 22.0571 \n",
      "Epoch 5/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 24.3830 \n",
      "Epoch 6/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 20.4229 \n",
      "Epoch 7/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 29.0867 \n",
      "Epoch 8/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 22.1799  \n",
      "Epoch 9/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 20.1839  \n",
      "Epoch 10/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 27.8353  \n",
      "Epoch 11/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 30.1377 \n",
      "Epoch 12/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 19.2985 \n",
      "Epoch 13/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 20.2793 \n",
      "Epoch 14/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 19.8723 \n",
      "Epoch 15/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 26.0026 \n",
      "Epoch 16/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 23.5106 \n",
      "Epoch 17/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 16.3772\n",
      "Epoch 18/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 26.0723 \n",
      "Epoch 19/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 18.5044 \n",
      "Epoch 20/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 24.5287 \n",
      "Epoch 21/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 24.8226 \n",
      "Epoch 22/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 15.5597 \n",
      "Epoch 23/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 18.2011 \n",
      "Epoch 24/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 20.7417 \n",
      "Epoch 25/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 14.1736 \n",
      "Epoch 26/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 14.3239 \n",
      "Epoch 27/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 19.0557  \n",
      "Epoch 28/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 17.1900 \n",
      "Epoch 29/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 18.3090 \n",
      "Epoch 30/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 14.5682 \n",
      "Epoch 31/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 14.1286 \n",
      "Epoch 32/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.8532 \n",
      "Epoch 33/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 13.6109 \n",
      "Epoch 34/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 13.9151 \n",
      "Epoch 35/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 14.5073 \n",
      "Epoch 36/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 10.2409\n",
      "Epoch 37/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 13.3541 \n",
      "Epoch 38/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.8544 \n",
      "Epoch 39/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.4662 \n",
      "Epoch 40/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 11.8396 \n",
      "Epoch 41/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.8465 \n",
      "Epoch 42/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.7018 \n",
      "Epoch 43/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.9765  \n",
      "Epoch 44/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.4349 \n",
      "Epoch 45/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.4380 \n",
      "Epoch 46/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.0929 \n",
      "Epoch 47/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.4940 \n",
      "Epoch 48/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.3659  \n",
      "Epoch 49/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.8162  \n",
      "Epoch 50/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.2831  \n",
      "Epoch 51/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.9159  \n",
      "Epoch 52/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.0654 \n",
      "Epoch 53/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.2305  \n",
      "Epoch 54/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5913 \n",
      "Epoch 55/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.8074 \n",
      "Epoch 56/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8634  \n",
      "Epoch 57/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6276 \n",
      "Epoch 58/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.3097 \n",
      "Epoch 59/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.4584 \n",
      "Epoch 60/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.3426 \n",
      "Epoch 61/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.3949 \n",
      "Epoch 62/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.5919 \n",
      "Epoch 63/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.5449 \n",
      "Epoch 64/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.3278 \n",
      "Epoch 65/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.0468 \n",
      "Epoch 66/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.9285 \n",
      "Epoch 67/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.0917 \n",
      "Epoch 68/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.6712 \n",
      "Epoch 69/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.2331 \n",
      "Epoch 70/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.7573 \n",
      "Epoch 71/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.9839 \n",
      "Epoch 72/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.0801 \n",
      "Epoch 73/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.2504 \n",
      "Epoch 74/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.5754 \n",
      "Epoch 75/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.2593 \n"
     ]
    }
   ],
   "source": [
    "h = model.fit(df.iloc[:, 0:-1].values, df['lpa'].values, epochs=75, verbose=1, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "708f0afd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0.37366673, 0.37366673],\n",
       "        [0.36545807, 0.36545807]], dtype=float32),\n",
       " array([0.27227923, 0.27227923], dtype=float32),\n",
       " array([[0.37286362],\n",
       "        [0.37286362]], dtype=float32),\n",
       " array([0.20472567], dtype=float32)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96fee339",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
